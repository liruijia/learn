{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liruijia/learn/blob/master/LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WVd3i51SLZg",
        "colab_type": "text"
      },
      "source": [
        " # 主题模型\n",
        "   从生成文档的角度来产生文档的主题，应用了大量的概率计算以及参数估计的方法来寻找每一篇文档的主题分布以及每个主题的词语分布情况。\n",
        "  \n",
        "\n",
        "1.   LDA模型中一篇文档的生成\n",
        "\n",
        "    在引入LDA模型的文档的生成过程前，先讲解一下PLSA模型的文档生成过程。\n",
        "    一篇文档可以有很多的主题，每个主题包含很多的词语，文档的生成我们可以看成是在摇骰子，先找到一个主题，然后再从该主题下摇到一个词语，反复这样摇N次，则可以形成一篇有N个字的文档。在此过程中文档的主题分布和每个主题的词语分布是事先给定的。\n",
        "    \n",
        "    LDA模型和PLSA模型不一样的是，LDA模型的“两个”分布是随机产生的。其随机分布均服从于迪利克雷分布。\n",
        "\n",
        "    LDA模型中（一篇）文档的生成过程为：\n",
        "    \n",
        "      step1： 在迪利克雷分布alpha中随机产生主题模型p1\n",
        "\n",
        "      step2： 从主题分布中取样生成文档i中第j个单词的主题Z_ij  (生成一个主题)\n",
        "\n",
        "      step3： 从狄利克雷分布beta中取样生成主题z_ij对应的词语分布\n",
        "\n",
        "      step4： 利用生成的词语分布生成词汇w_ij\n",
        "\n",
        "\n",
        "2.   LDA模型的具体步骤\n",
        "    \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU1u5WDqRgdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}