{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "需要注意的是情感大分类这个地方和我们模型中的情感的个数是不一致的，所有的词语都可以分为这7种类型\n",
    "但是我们在进行情感分析的时候有的时候只需要其中的几类就可以比如说是，只研究情感极性\n",
    "或者只研究喜怒哀乐这4个方面，在使用模型的时候还得看情况使用\n",
    "大分类：按照文件来的\n",
    "极性：褒义、贬义、中性、间有  0:中性，1：褒义，2：贬义，3：兼有\n",
    "情感态度：正面 反面： 0：正面  1：反面\n",
    "情感表达：喜怒哀乐  1--表示喜  2----表示怒，3------表示哀 4 ------表示乐\n",
    "\n",
    "需要注意的是我们找到在训练LDA模型的时候，我们通过其情感大分类则可以知道其相应的情感大分类——表达\n",
    "以及情感分类——态度   ，无须保留\n",
    "这些值如何更新？？？？我们在训练的时候可以利用词典赋予新的情感标签（如果能找到的话则使用若找不到，则随机赋予），但是在采样过程中，\n",
    "得到了新的情感标签的时候，我们可以要更新这个词在词库里的信息，最后进行保存，查看区别！！！！\n",
    "对于那些没有的词我们也要保留其信息，进行后期验证\n",
    "强度没有办法进行更新只能每次相应的修改\n",
    "'''\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import sys\n",
    "sys.path.append('G:/anconada/envs/py36/lib/site-packages')\n",
    "from gensim.models  import word2vec\n",
    "from sklearn.feature_extraction.text  import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import json\n",
    "import psutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class sentiment_dict():\n",
    "    def __init__(self):\n",
    "       print('开始处理情感词典')\n",
    "\n",
    "    def get_data(self,path_list):\n",
    "        final_data0=[]\n",
    "        #final_corpus=[]\n",
    "        data1 = pd.read_csv(path_list[1], engine='python')\n",
    "        final_data0.append(data1['词语'].tolist())\n",
    "\n",
    "        for path in path_list[2:]:\n",
    "            final_data0.append(self._load_senti_dict(path))\n",
    "\n",
    "        with open(path_list[0], 'r', encoding='utf-8') as f:\n",
    "            for line in f.readlines():\n",
    "                lines = line.strip().split(' ')\n",
    "                final_data0.append(lines)\n",
    "            f.close()\n",
    "\n",
    "        with open('C:/Users/Administrator/Desktop/data/评论/final_corpus.txt', 'w', encoding='utf-8') as f:\n",
    "            for line in final_data0:\n",
    "                f.write(' '.join(line))\n",
    "                f.write('\\n')\n",
    "            f.close()\n",
    "        print('所有情感词典加载完毕*******************')\n",
    "        return final_data0\n",
    "\n",
    "    def _load_senti_dict(self,path):\n",
    "        data=[]\n",
    "        with open(path,'r',encoding='utf-8') as f :\n",
    "            for line  in f.readlines():\n",
    "                if line[0].isdigit():\n",
    "                    continue\n",
    "                else:\n",
    "                    if line != '\\n':\n",
    "                        data.extend(line.strip().split(' '))\n",
    "            f.close()\n",
    "        data.pop(0)\n",
    "        print(path[-15:]+'加载完毕**************')\n",
    "        return data\n",
    "\n",
    "    def load_amend_dict(self,data_1, final_data0):\n",
    "        final_data = dict()\n",
    "        dict_word = data_1['词语'].tolist()\n",
    "        # print(data_2[:30])\n",
    "        for i, doc in enumerate(final_data0):\n",
    "            for j, word in enumerate(doc):\n",
    "                if word in final_data.keys() or word == ' ' or word == '':\n",
    "                    continue\n",
    "                else:\n",
    "                    final_data[word] = []\n",
    "                    if word in dict_word:\n",
    "                        index = dict_word.index(word)\n",
    "                        final_data[word] = data_1[['情感大分类', '强度']].loc[index].tolist()\n",
    "                    else:\n",
    "                        # print('word :{0} not in vocabulary'.format(word))\n",
    "                        sim_word = model.most_similar(word, topn=1)[0]\n",
    "                        if sim_word in dict_word:\n",
    "                            final_data[word] = final_data[sim_word]\n",
    "                            # print('word:{0} can find similar word :{1}'.format(word,sim_word))\n",
    "                        else:\n",
    "                            # print('word:{0} can not find similar word'.format(word))\n",
    "                            sentiment_lable=random.randint(1,7)\n",
    "                            power_lable=3\n",
    "                            final_data[word]=[sentiment_lable,power_lable]\n",
    "\n",
    "\n",
    "        print('词语词典建立完成*************')\n",
    "        return final_data\n",
    "if __name__=='__main__':\n",
    "    path0='C:/Users/Administrator/Desktop/data/评论/cut_comment_1.txt'\n",
    "    path1 = 'C:/Users/Administrator/Desktop/data/情感词汇本体/情感词汇本体.csv'\n",
    "    path2 = 'C:/Users/Administrator/Desktop/data/情感字典/知网Hownet情感词典/正面情感词语（中文）.txt'\n",
    "    path3 = 'C:/Users/Administrator/Desktop/data/情感字典/知网Hownet情感词典/负面情感词语（中文）.txt'\n",
    "    path4 = 'C:/Users/Administrator/Desktop/data/情感字典/知网Hownet情感词典/程度级别词语（中文）.txt'\n",
    "    path5 = 'C:/Users/Administrator/Desktop/data/情感字典/知网Hownet情感词典/正面评价词语（中文）.txt'\n",
    "    path6 = 'C:/Users/Administrator/Desktop/data/情感字典/知网Hownet情感词典/负面评价词语（中文）.txt'\n",
    "\n",
    "    path_list = [path0,path1,path2, path3, path4, path5, path6]\n",
    "\n",
    "    #vector=CountVectorizer()\n",
    "    #trans=TfidfTransformer()\n",
    "    #tfidf = trans.fit_transform(vector.fit_transform(final_corpus))\n",
    "    #word = vector.get_feature_names()  #\n",
    "    #weight = tfidf.toarray()\n",
    "\n",
    "    P=sentiment_dict()\n",
    "    final_data0=P.get_data(path_list)\n",
    "    path01='C:/Users/Administrator/Desktop/data/评论/final_corpus.txt'\n",
    "    sentences=word2vec.Text8Corpus(path01)\n",
    "    model= word2vec.Word2Vec(sentences,size=400,window=5,min_count=1)\n",
    "\n",
    "    data1=pd.read_csv(path1,engine='python')\n",
    "    df_info=pd.DataFrame(columns=['情感分类'])\n",
    "    ui=data1['情感分类'].unique().tolist()\n",
    "    for uu in ui:\n",
    "        if uu==None:\n",
    "            ui.pop(ui.index(None))\n",
    "    df_info['情感分类']=ui\n",
    "    df_info['情感大分类']=df_info['情感分类'].map({'PA':1,'PE':1,\n",
    "                                             'PD':2, 'PH':2, 'PG':2, 'PB':2, 'PK':2,\n",
    "                                        'NA':3,'NB':4,'NT':4,'NH':4,'PF':4,'NI':5,'NC':5,'NG':5,\n",
    "                                            'NE':6,'ND':6,'NN':6,'NK':6,'NL':6,'PC':7})\n",
    "    data1['情感大分类']=data1['情感分类'].map({'PA':1,'PE':1,\n",
    "                                             'PD':2, 'PH':2, 'PG':2, 'PB':2, 'PK':2,\n",
    "                                        'NA':3,'NB':4,'NT':4,'NH':4,'PF':4,'NI':5,'NC':5,'NG':5,\n",
    "                                            'NE':6,'ND':6,'NN':6,'NK':6,'NL':6,'PC':7})\n",
    "    df_info['情感大分类_表达']=df_info['情感大分类'].map({2:1,3:2,6:2,4:3,5:3,7:3,1:4})\n",
    "    df_info['情感大分类_态度']=df_info['情感大分类'].map({1:0,2:0,3:1,4:1,5:1,6:1,7:1})\n",
    "    #print(df_info)\n",
    "\n",
    "    df_info.to_csv('C:\\\\Users\\\\Administrator\\\\Desktop\\\\data\\\\评论\\\\df_info.csv')\n",
    "\n",
    "    final_info_sentword=P.load_amend_dict(data1,final_data0)\n",
    "    with open('C:\\\\Users\\\\Administrator\\\\Desktop\\\\data\\\\评论\\\\final_info_sentword.txt','w',encoding='utf-8') as fw:\n",
    "        fw.write(str(final_info_sentword)) #也可以直接使用这种方法\n",
    "\n",
    "    print(final_info_sentword['OPPO'])\n",
    "    items=model.most_similar(u'好评',topn=20)\n",
    "    print('“好评”一词的相似的词语')\n",
    "    for word ,sim_par in items:\n",
    "        print(word,sim_par)\n",
    "\n",
    "    print('没有删除对象之前的内存占用情况**************')\n",
    "    info = psutil.virtual_memory()\n",
    "    print('*' * 30)\n",
    "    print(u'内存使用：', psutil.Process(os.getpid()).memory_info().rss)\n",
    "    print(u'总内存：', info.total)\n",
    "    print(u'内存占比：', info.percent)\n",
    "    print(u'cpu个数：', psutil.cpu_count())\n",
    "\n",
    "    del items\n",
    "    del final_info_sentword\n",
    "    del df_info\n",
    "    del data1\n",
    "    del sentences\n",
    "    print('删除了 items,final_info_sentword,df_info,data1,sentences')\n",
    "\n",
    "    print('删除内存之后的内存占用情况********')\n",
    "    print(u'内存使用：', psutil.Process(os.getpid()).memory_info().rss)\n",
    "    print(u'总内存：', info.total)\n",
    "    print(u'内存占比：', info.percent)\n",
    "    print(u'cpu个数：', psutil.cpu_count())sssssss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
